# Lista de Exercícios 4

#### Professor
![Helio](https://img.shields.io/badge/Helio_Crestana_Guardia-%2300599C.svg?style=for-the-badge&logo=GoogleScholar&logoColor=white)


## GPU e CUDA

### O que é uma GPU?

### 2. Como são organizados os elementos de processamento em GPUs NVIDIA?

### 3. Como é organizada a hierarquia de memória em GPUs NVIDIA?

### 4. O que é um Stream Multiprocessor (SM)?

### 5. De que maneira a *capability* de uma GPU está relacionada às suas características de processamento?

### 6. O que é CUDA?

### 7. Como é o modelo de programas com CUDA?

### 8. Como são reservadas áreas de memória na GPU para uso pelas *threads*? Como essas áreas são liberadas?

### 9. De que maneira dados são passados da memória do *host* (CPU) para a memória da GPU?

### 10. Como funciona o modelo de memória unificada (*Unified Memory*) CUDA?

### 11. Como funciona o modelo de execução de código em GPU usando CUDA?

### 12. Como funciona o modelo SIMT em CUDA?

### 13. O que é um *kernel* CUDA?

### 14. Como são organizadas as *threads* para execução na GPU?

### 15. O que é um *grid de threads*?

### 16. Quais são as dimensões máximas de um *grid*?

### 17. O que é um bloco de *threads* na ativação de um *kernel*?

### 18. Quais são as dimensões máximas de um bloco de *treads*?

### 19. De que maneira uma *thread* CUDA é identificada logicamente?

### 20. Como são passados parâmetros para a função do *kernel* em sua ativação?

### 21. De que maneira a execução de blocos de *threads* se relaciona com SMs?

### 22. Como ocorre a execução de *threads* dentro de um SM?

### 23. O que é um *warp*?

### 24. Como ocorre a execução de instruções nos *warps*?

### 25. Como é a coordenação das instruções das *threads* de uma *warp*?

### 26. Como pode ser feito o mapeamento de uma estrutura unidimensional para processamento com diferentes *threads*?

### 27. Como os identificadores das *threads* podem ser linearizados?

### 28. Como é o sincronismo entre a execução de atividades no *host* (CPU) e no *device* (GPU)?

### 29. Como é possível ao programa CUDA executando no *host* saber sobre a conclusão da execução de um *kernel*?

## Contato

Se você tiver alguma dúvida, sugestão ou precisar de suporte, por favor, sinta-se à vontade para entrar em contato conosco:

- **E-mail:** petbcc.ufscar@gmail.com

Você também pode criar uma **Issue** no [GitHub](https://github.com/petbccufscar/pet-colab/issues) para relatar problemas, sugerir melhorias ou contribuir para o desenvolvimento do PET-COLAB. Estamos sempre abertos para receber feedback e colaboração. Obrigado!